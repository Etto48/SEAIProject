{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Optional\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.utils.data import IterableDataset, Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from split_CIFAR10 import SplitCIFAR10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SplitCIFAR10(task_duration=10000)\n",
    "test_dataset = SplitCIFAR10(task_duration=1000, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullClassifier(nn.Module):\n",
    "    def __init__(self, in_out_shape=(3, 32, 32), classes=10, tasks=1):\n",
    "        super(FullClassifier, self).__init__()\n",
    "        self.conv_depth = 3\n",
    "        self.ff_depth = 3\n",
    "        self.conv_width = 32\n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.append(nn.BatchNorm2d(in_out_shape[0]))\n",
    "        self.conv.append(nn.Conv2d(in_out_shape[0], self.conv_width, kernel_size=3, stride=1, padding=1, padding_mode=\"reflect\"))\n",
    "        width = self.conv_width\n",
    "        for i in range(self.conv_depth):\n",
    "            self.conv.append(nn.Conv2d(width, 2*width, kernel_size=3, stride=1, padding=1, padding_mode=\"reflect\"))\n",
    "            self.conv.append(nn.BatchNorm2d(2*width))\n",
    "            self.conv.append(nn.ReLU())\n",
    "            self.conv.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            width *= 2\n",
    "        \n",
    "        self.conv.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.conv.append(nn.Flatten())\n",
    "        \n",
    "        self.ff = nn.Sequential()\n",
    "        for i in range(self.ff_depth):\n",
    "            self.ff.append(nn.Linear(width, width))\n",
    "            self.ff.append(nn.BatchNorm1d(width))\n",
    "            self.ff.append(nn.ReLU())\n",
    "        \n",
    "        self.heads_in = width\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(tasks):\n",
    "            self.heads.append(nn.Linear(width, classes))\n",
    "\n",
    "    def add_head(self, classes: int):\n",
    "        self.heads.append(nn.Linear(self.heads_in, classes))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv(x)\n",
    "        x = self.ff(x)\n",
    "        out = []\n",
    "        for i in range(len(self.heads)):\n",
    "            out.append(self.heads[i](x))\n",
    "        return out     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWFClassifier(nn.Module):\n",
    "    def __init__(self, in_out_shape=(3, 32, 32), classes=10):\n",
    "        super(LWFClassifier, self).__init__()\n",
    "\n",
    "        self.old_model: Optional[FullClassifier] = None\n",
    "        self.classes = classes\n",
    "        self.model = FullClassifier(in_out_shape, classes)\n",
    "        self.optimizer_params = {\n",
    "            \"lr\": 1e-3,\n",
    "            \"momentum\": 0.9,\n",
    "            \"weight_decay\": 0.0005\n",
    "        }\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), **self.optimizer_params)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.loss_old = lambda logx, logy: -torch.sum(torch.softmax(logy, dim=1) * torch.log_softmax(logx, dim=1), dim=1).mean()\n",
    "\n",
    "        self.error_window_max_len = 32\n",
    "        self.error_threshold = 10\n",
    "        self.error_window = []\n",
    "        self.accuracy_window = []\n",
    "        self.error_window_sum = 0\n",
    "        self.accuracy_window_sum = 0\n",
    "\n",
    "        self.temperature = 2\n",
    "        self.old_loss_weight = 2\n",
    "\n",
    "    def new_error(self, error: float, accuracy: float) -> tuple[float, float]:\n",
    "        if len(self.error_window) >= self.error_window_max_len:\n",
    "            self.error_window_sum -= self.error_window.pop(0)\n",
    "            self.accuracy_window_sum -= self.accuracy_window.pop(0)\n",
    "        self.error_window.append(error)\n",
    "        self.accuracy_window.append(accuracy)\n",
    "        self.error_window_sum += error\n",
    "        self.accuracy_window_sum += accuracy\n",
    "\n",
    "        mean = self.error_window_sum / len(self.error_window)\n",
    "        accuracy_mean = self.accuracy_window_sum / len(self.accuracy_window)\n",
    "        std = (sum((x - mean) ** 2 for x in self.error_window) / len(self.error_window)) ** 0.5\n",
    "        return mean, std, accuracy_mean\n",
    "    \n",
    "    def new_task(self, classes: int):\n",
    "        \"\"\"Adds a new task to the model and freezes the old model.\n",
    "        The number of classes can differ between tasks.\n",
    "        \"\"\"\n",
    "\n",
    "        self.old_model = copy.deepcopy(self.model)\n",
    "        self.model.add_head(classes)\n",
    "        for param in self.old_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.old_model.eval()\n",
    "        self.model.train()\n",
    "        self.classes = classes\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), **self.optimizer_params)\n",
    "        self.error_window = []\n",
    "        self.accuracy_window = []\n",
    "        self.error_window_sum = 0\n",
    "        self.accuracy_window_sum = 0\n",
    "        self.batches_with_high_loss = 0\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x_new = self.model(x)\n",
    "        x_old = self.old_model(x) if self.old_model is not None else []\n",
    "        return x_new, x_old\n",
    "\n",
    "    def predict(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Returns the indices of the predicted classes for each task in the batch.\"\"\"\n",
    "\n",
    "        x = self.model(x)\n",
    "        \n",
    "        output = torch.zeros_like(t, dtype=torch.long)\n",
    "        for batch_index in range(t.shape[0]):\n",
    "            task_id = t[batch_index]\n",
    "            if task_id >= len(x):\n",
    "                raise ValueError(f\"Task id {task_id} out of range\")\n",
    "            output[batch_index] = x[task_id][batch_index].argmax(dim=0)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def test(self, test_loader: DataLoader):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            loading_bar = tqdm(test_loader, desc=\"Testing\", total=len(test_loader))\n",
    "            confusion_matrix = torch.zeros(10, 10, dtype=torch.int64)\n",
    "            for x, y, t in loading_bar:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                t = t.to(device)\n",
    "                known_tasks_mask = t < len(self.model.heads)\n",
    "                if not known_tasks_mask.any():\n",
    "                    continue\n",
    "                x = x[known_tasks_mask]\n",
    "                y = y[known_tasks_mask]\n",
    "                t = t[known_tasks_mask]\n",
    "                outputs = self.predict(x, t)\n",
    "                total += y.shape[0]\n",
    "                correct += (outputs == y).sum().item()\n",
    "                accuracy = correct / total\n",
    "                confusion_matrix += torch.bincount(y * 10 + outputs, minlength=100).reshape(10, 10)\n",
    "                loading_bar.set_postfix(accuracy=f\"{accuracy:.2%}\")\n",
    "        return confusion_matrix\n",
    "\n",
    "    def fit(self, train_dataset: IterableDataset, test_dataset: IterableDataset):\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "        \n",
    "        loading_bar = tqdm(train_loader, desc=\"Training\", unit=\"batch\")\n",
    "        mean, std = 0, 0\n",
    "        task_changes = 0\n",
    "        confusion_matrices = []\n",
    "        for batch in loading_bar:\n",
    "            self.model.train()\n",
    "            img, label, task = batch\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            task = task.to(device)\n",
    "\n",
    "            max_task_id = task.max().item()\n",
    "            if max_task_id > task_changes:\n",
    "                confusion_matrices.append(self.test(test_loader))\n",
    "                self.new_task(self.classes)\n",
    "                task_changes += 1\n",
    "                continue # skip this batch for simplicity, this batch might contain mixed tasks\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            output, old_output = self(img)\n",
    "            loss, loss_new, loss_old = self.criterion(output, old_output, label)\n",
    "            accuracy = (output[-1].argmax(dim=1) == label).sum().item() / label.shape[0]\n",
    "            mean, std, accuracy_mean = self.new_error(loss_new.item(), accuracy)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loading_bar.set_postfix({\n",
    "                \"acc_mean\": f\"{accuracy_mean:.2%}\",\n",
    "                \"l_new\": f\"{loss_new.item():.3f}\", \n",
    "                \"l_old\": f\"{loss_old.item():.3f}\", \n",
    "                \"mean\": f\"{mean:.3f}\", \n",
    "                \"std\": f\"{std:.3f}\",\n",
    "                \"n\": task_changes})\n",
    "        confusion_matrices.append(self.test(test_loader))\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        for i, confusion_matrix in enumerate(confusion_matrices):\n",
    "            plt.subplot(1, len(confusion_matrices), i + 1)\n",
    "            plt.imshow(confusion_matrix.cpu(), interpolation='nearest')\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            plt.xlabel(\"Predicted Label\")\n",
    "            if i == 0:\n",
    "                plt.ylabel(\"True Label\")\n",
    "            plt.xticks(np.arange(10))\n",
    "            if i == 0:\n",
    "                plt.yticks(np.arange(10))\n",
    "            else:\n",
    "                plt.yticks([])\n",
    "        plt.show()\n",
    "    \n",
    "    def criterion(self, output: list[torch.Tensor], old_output: list[torch.Tensor], target: torch.Tensor):\n",
    "        loss_new = self.loss(output[-1], target)\n",
    "        loss_old = torch.zeros_like(loss_new)\n",
    "        for i in range(len(old_output)):\n",
    "            loss_old += self.old_loss_weight * self.loss_old(output[i], old_output[i])\n",
    "        return loss_new + loss_old, loss_new, loss_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LWFClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
