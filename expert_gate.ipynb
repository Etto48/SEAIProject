{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import IterableDataset, Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from expert import ExpertMLP\n",
    "from gate import GateAutoencoder\n",
    "from split_MNIST import SplitMNIST\n",
    "from split_CIFAR10 import SplitCIFAR10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SplitMNIST()\n",
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=train_dataset.transform, target_transform=torch.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GateAutoencoder(nn.Module):\n",
    "    def __init__(self, in_out_shape=(3,32,32),  depth=3, ff_depth=3, conv_hidden_dim=64, hidden_dim=128, latent_dim=128):\n",
    "        super(GateAutoencoder, self).__init__()\n",
    "        self.input_features = in_out_shape[0]\n",
    "        self.depth = depth\n",
    "        self.ff_depth = ff_depth\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.conv_hidden_dim = conv_hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential()\n",
    "        self.decoder = nn.Sequential()\n",
    "        latent_width, latent_height = in_out_shape[1] // (2**depth), in_out_shape[2] // (2**depth)\n",
    "        self.encoder.append(nn.Conv2d(self.input_features, conv_hidden_dim, kernel_size=3, padding=1, padding_mode='reflect'))\n",
    "        for i in range(depth):\n",
    "            self.encoder.append(nn.Conv2d(conv_hidden_dim, conv_hidden_dim, kernel_size=4, padding=1, stride=2, padding_mode='reflect'))\n",
    "            self.encoder.append(nn.BatchNorm2d(conv_hidden_dim))\n",
    "            self.encoder.append(nn.ReLU())\n",
    "        self.encoder.append(nn.Flatten())\n",
    "        for i in range(ff_depth):\n",
    "            if i == 0:\n",
    "                in_features = conv_hidden_dim * latent_width * latent_height\n",
    "            else:\n",
    "                in_features = hidden_dim\n",
    "            if i == ff_depth - 1:\n",
    "                out_features = latent_dim\n",
    "            else:\n",
    "                out_features = hidden_dim\n",
    "            self.encoder.append(nn.Linear(in_features, out_features))\n",
    "            self.encoder.append(nn.BatchNorm1d(out_features))\n",
    "            if i != ff_depth - 1:\n",
    "                self.encoder.append(nn.ReLU())\n",
    "            else:\n",
    "                self.encoder.append(nn.Tanh())\n",
    "\n",
    "        for i in range(ff_depth):\n",
    "            if i == 0:\n",
    "                in_features = latent_dim\n",
    "            else:\n",
    "                in_features = hidden_dim\n",
    "            if i == ff_depth - 1:\n",
    "                out_features = conv_hidden_dim * latent_width * latent_height\n",
    "            else:\n",
    "                out_features = hidden_dim\n",
    "            self.decoder.append(nn.Linear(in_features, out_features))\n",
    "            self.decoder.append(nn.BatchNorm1d(out_features))\n",
    "            self.decoder.append(nn.ReLU())\n",
    "        self.decoder.append(nn.Unflatten(1, (conv_hidden_dim, latent_width, latent_height)))\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.decoder.append(nn.ConvTranspose2d(conv_hidden_dim, conv_hidden_dim, kernel_size=4, padding=1, stride=2))\n",
    "            self.decoder.append(nn.BatchNorm2d(conv_hidden_dim))\n",
    "            self.decoder.append(nn.ReLU())\n",
    "        self.decoder.append(nn.Conv2d(conv_hidden_dim, self.input_features, kernel_size=3, padding=1, padding_mode='reflect'))\n",
    "        self.decoder.append(nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if self.training:\n",
    "            x = x + torch.randn_like(x) * 0.1\n",
    "        latent = self.encoder(x)\n",
    "        x = self.decoder(latent)\n",
    "        return x, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertMLP(nn.Module):\n",
    "\tdef __init__(self, input_feature: int, depth: int, hidden_features: int, output_features: int):\n",
    "\t\tsuper(ExpertMLP, self).__init__()\n",
    "\t\t\n",
    "\t\tself.model = nn.Sequential()\n",
    "\t\tfor i in range(depth):\n",
    "\t\t\tin_features = input_feature if i == 0 else hidden_features\n",
    "\t\t\tout_features = hidden_features\n",
    "\t\t\tself.model.append(nn.Linear(in_features, out_features))\n",
    "\t\t\tself.model.append(nn.BatchNorm1d(out_features))\n",
    "\t\t\tself.model.append(nn.ReLU())\n",
    "\t\tself.model.append(nn.Linear(hidden_features, output_features))\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\treturn self.model(x)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedExpert(nn.Module):\n",
    "    def __init__(self, in_out_shape=(1, 28, 28), classes=10, depth=2, ff_depth=3, expert_depth=3, hidden_dim=64, latent_dim=128):\n",
    "        super(GatedExpert, self).__init__()\n",
    "        self.gates = nn.ModuleList()\n",
    "        self.experts = nn.ModuleList()\n",
    "        self.gate_optimizers = []\n",
    "        self.expert_optimizers = []\n",
    "        self.in_out_shape = in_out_shape\n",
    "        self.classes = classes\n",
    "        self.depth = depth\n",
    "        self.ff_depth = ff_depth\n",
    "        self.expert_depth = expert_depth\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.selection_softmax = nn.Softmax(dim=0)\n",
    "        self.gate_loss = nn.L1Loss(reduction='none')\n",
    "        self.expert_loss = nn.CrossEntropyLoss()\n",
    "        self.new_task_boost = 100\n",
    "\n",
    "        self.error_window = []\n",
    "        self.error_window_size = 32\n",
    "        self.error_window_sum = 0\n",
    "\n",
    "        self.error_std_threshold = 4\n",
    "        self.error_flat_threshold = 0.01\n",
    "\n",
    "        self.fine_tune = False\n",
    "\n",
    "        self.new_task()\n",
    "\n",
    "    def add_error(self, error) -> tuple[float, float]:\n",
    "        if len(self.error_window) >= self.error_window_size:\n",
    "            self.error_window_sum -= self.error_window.pop(0)\n",
    "        self.error_window.append(error)\n",
    "        self.error_window_sum += error\n",
    "        mean = self.error_window_sum / len(self.error_window)\n",
    "        std = (sum((error - mean) ** 2 for error in self.error_window) / len(self.error_window)) ** 0.5\n",
    "        return mean, std\n",
    "\n",
    "    def reset_error_window(self):\n",
    "        self.error_window = []\n",
    "        self.error_window_sum = 0\n",
    "\n",
    "    def new_task(self):\n",
    "        self.time_since_new_task = 0\n",
    "        gate = copy.deepcopy(self.gates[-1]) if len(self.gates) > 0 and self.fine_tune else GateAutoencoder(\n",
    "            in_out_shape=self.in_out_shape,\n",
    "            depth=self.depth,\n",
    "            ff_depth=self.ff_depth,\n",
    "            conv_hidden_dim=self.hidden_dim,\n",
    "            hidden_dim=self.hidden_dim * 16,\n",
    "            latent_dim=self.latent_dim\n",
    "        )\n",
    "        self.gates.append(gate)\n",
    "        expert = copy.deepcopy(self.experts[-1]) if len(self.experts) > 0 and self.fine_tune else ExpertMLP(\n",
    "            input_feature=self.latent_dim,\n",
    "            depth=self.expert_depth,\n",
    "            hidden_features=self.hidden_dim,\n",
    "            output_features=self.classes\n",
    "        )\n",
    "        self.experts.append(expert)\n",
    "        self.gate_optimizers.append(torch.optim.Adam(gate.parameters(), lr=1e-3))\n",
    "        self.expert_optimizers.append(torch.optim.Adam(expert.parameters(), lr=1e-3))\n",
    "        self.reset_error_window()\n",
    "    \n",
    "    def forward_gates(self, x: torch.Tensor):\n",
    "        # x (B, C, H, W)\n",
    "        latent_representations = []\n",
    "        reconstructions = []\n",
    "        reconstruction_errors = []\n",
    "        for gate in self.gates:\n",
    "            recon, latent = gate(x)\n",
    "            latent_representations.append(latent)\n",
    "            reconstructions.append(recon)\n",
    "            error = self.gate_loss(recon, x)\n",
    "            error = error.mean(dim=(1, 2, 3))\n",
    "            reconstruction_errors.append(error)\n",
    "\n",
    "        # reconstruction_errors (N_gates, B)\n",
    "        reconstruction_errors = torch.stack(reconstruction_errors, dim=0)\n",
    "        reconstructions = torch.stack(reconstructions, dim=0)\n",
    "        # latent_representations (N_gates, B, latent_dim)\n",
    "        latent_representations = torch.stack(latent_representations, dim=0)\n",
    "        return reconstructions, latent_representations, reconstruction_errors\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor, latent_representations: torch.Tensor):\n",
    "        # classes (B, classes)\n",
    "        logits = torch.zeros(x.shape[0], self.classes)\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            if torch.all(~mask[i]):\n",
    "                continue\n",
    "            expert_input = latent_representations[i][mask[i]]\n",
    "            expert_output = expert(expert_input)\n",
    "            logits[mask[i]] = expert_output\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def mask_from_recon_errors(self, reconstruction_errors: torch.Tensor):\n",
    "        last_task_boost = torch.zeros_like(reconstruction_errors)\n",
    "        if self.training:\n",
    "            last_task_boost[-1] = self.new_task_boost\n",
    "        min_reconstruction_errors, indices = torch.min(reconstruction_errors - last_task_boost, dim=0)\n",
    "        mask = torch.arange(len(self.gates)).unsqueeze(1) == indices.unsqueeze(0)\n",
    "        return mask, min_reconstruction_errors\n",
    "\n",
    "    def mask_from_task_ids(self, task_ids: torch.Tensor):\n",
    "        max_task_id = max(task_ids.max(), len(self.gates) - 1)\n",
    "        mask = torch.arange(max_task_id + 1).unsqueeze(1) == task_ids.unsqueeze(0)\n",
    "        return mask\n",
    "\n",
    "    def predict(self, x: torch.Tensor):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            reconstructions, latent_representations, reconstruction_errors = self.forward_gates(x)\n",
    "            mask, _ = self.mask_from_recon_errors(reconstruction_errors)\n",
    "            logits = self.forward(x, mask, latent_representations)\n",
    "            return logits, reconstructions\n",
    "\n",
    "    def fit(self, train_dataset: IterableDataset, test_dataset: Dataset | None = None):\n",
    "        train_loader = DataLoader(train_dataset, batch_size=16)\n",
    "        if test_dataset is not None:\n",
    "            test_loader = DataLoader(test_dataset, batch_size=64, generator=torch.Generator(device=device))\n",
    "\n",
    "        loading_bar = tqdm(train_loader, total=len(train_loader), desc=\"Training\", unit=\"batch\")\n",
    "        mean, std = 0, 0\n",
    "        accuracy = 0\n",
    "        for i, batch in enumerate(loading_bar):\n",
    "            images, targets, task_ids = batch\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            reconstructions, latent_representations, reconstruction_errors = self.forward_gates(images)\n",
    "            mask, _ = self.mask_from_recon_errors(reconstruction_errors)\n",
    "            avg_selected_recon_errors = reconstruction_errors[mask].mean().item()\n",
    "\n",
    "            if len(self.error_window) == self.error_window_size and avg_selected_recon_errors > mean + self.error_std_threshold * std + self.error_flat_threshold:\n",
    "                self.new_task()\n",
    "                reconstructions, latent_representations, reconstruction_errors = self.forward_gates(images)\n",
    "                mask, _ = self.mask_from_recon_errors(reconstruction_errors)\n",
    "                avg_selected_recon_errors = reconstruction_errors[mask].mean().item()\n",
    "\n",
    "            mean, std = self.add_error(avg_selected_recon_errors)\n",
    "\n",
    "            self.train()\n",
    "            for j in range(len(self.gates)):\n",
    "                if mask[j].sum() < 2: # exclude empty batches and single samples to avoid BatchNorm errors\n",
    "                    continue\n",
    "                self.gate_optimizers[j].zero_grad()\n",
    "                self.expert_optimizers[j].zero_grad()\n",
    "                images_j = images[mask[j]]\n",
    "                targets_j = targets[mask[j]]\n",
    "                recon, latent = self.gates[j](images_j)\n",
    "                expert_output = self.experts[j](latent.detach())\n",
    "                correct = (expert_output.argmax(dim=1) == targets_j).sum().item()\n",
    "                total = targets_j.shape[0]\n",
    "                accuracy = (correct / total) * 0.1 + accuracy * 0.9\n",
    "                gate_loss = self.gate_loss(recon, images_j).mean()\n",
    "                expert_loss = self.expert_loss(expert_output, targets_j)\n",
    "                gate_loss.backward()\n",
    "                expert_loss.backward()\n",
    "                self.gate_optimizers[j].step()\n",
    "                self.expert_optimizers[j].step()\n",
    "                \n",
    "            loading_bar.set_postfix({\n",
    "                #\"loss\": f\"{loss.item():.3f}\", \n",
    "                \"e\": f\"{expert_loss.item():.3f}\", \n",
    "                \"g\": f\"{gate_loss.item():.3f}\", \n",
    "                \"n\": len(self.gates),\n",
    "                \"mean\": f\"{mean:.3f}\",\n",
    "                \"std\": f\"{std:.3f}\",\n",
    "                \"acc\": f\"{accuracy:.2%}\"})\n",
    "        if test_dataset is not None:\n",
    "            self.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                loading_bar = tqdm(test_loader, desc=\"Testing\", total=len(test_loader))\n",
    "                confusion_matrix = torch.zeros(10, 10, dtype=torch.int64)\n",
    "                for x, y in loading_bar:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "                    logits, reconstructions = self.predict(x)\n",
    "                    outputs = logits\n",
    "                    total += y.shape[0]\n",
    "                    correct += (outputs.argmax(dim=1) == y).sum().item()\n",
    "                    accuracy = correct / total\n",
    "                    confusion_matrix += torch.bincount(y * 10 + outputs.argmax(dim=1), minlength=100).reshape(10, 10)\n",
    "                    loading_bar.set_postfix(accuracy=f\"{accuracy:.2%}\")\n",
    "            \n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(confusion_matrix.cpu(), interpolation='nearest')\n",
    "            plt.colorbar()\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            plt.xlabel(\"Predicted Label\")\n",
    "            plt.ylabel(\"True Label\")\n",
    "            plt.xticks(np.arange(10))\n",
    "            plt.yticks(np.arange(10))\n",
    "            plt.show()\n",
    "            # demo some images and autoencode them with all gates\n",
    "            original_images = []\n",
    "            while len(original_images) < 10:\n",
    "                for i in range(len(test_dataset)):\n",
    "                    img, label = test_dataset[i]\n",
    "                    if label == len(original_images):\n",
    "                        original_images.append((img, label))\n",
    "            original_images = torch.stack([img for img, _ in original_images], dim=0).to(device)\n",
    "            reconstructions = []\n",
    "            for gate in self.gates:\n",
    "                recon, _ = gate(original_images)\n",
    "                reconstructions.append(recon)\n",
    "            reconstructions = torch.stack(reconstructions, dim=0)\n",
    "            original_images = original_images.detach().cpu().numpy()\n",
    "            reconstructions = reconstructions.detach().cpu().numpy()\n",
    "            fig, axes = plt.subplots(len(self.gates)+1, 10)\n",
    "            for i in range(10):\n",
    "                axes[0, i].imshow(original_images[i].transpose(1, 2, 0), cmap='gray')\n",
    "                axes[0, i].axis('off')\n",
    "                for j in range(len(self.gates)):\n",
    "                    axes[j + 1, i].imshow(reconstructions[j, i].transpose(1, 2, 0), cmap='gray')\n",
    "                    axes[j + 1, i].axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GatedExpert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
