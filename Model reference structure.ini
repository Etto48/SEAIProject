Model reference structure.py

herocod@herocod-laptop-power:~/Documents/UniPi/SEAI/SEAIProject/In_defence_of_LWF/hat/src$ python run.py --experiment only_cifar100 --approach lwf --arch wide-resnet20-w8 --aug aug-v1 --nepochs 200
 --task_size 5 --lr 0.01 --parameter 1,2
====================================================================================================
Arguments =
        seed: 0
        experiment: only_cifar100
        approach: lwf
        arch: wide-resnet20-w8
        output: ../res/only_cifar100_lwf-wide-resnet20-w8_0_aug-v1_2025-05-18__14-32-31_PGAV7LGYCM.txt
        nepochs: 200
        task_size: 5
        lr: 0.01
        parameter: 1,2
        aug: aug-v1
        disable_data_augment: False
====================================================================================================
Load data...
Classes order = [26, 86, 2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13, 7, 30, 22, 24, 33, 8, 43, 62, 3, 71, 45, 48, 6, 99, 82, 76, 60, 80, 90, 68, 51, 27, 18, 56, 63, 74, 1, 61, 42, 41, 4, 15, 17, 40, 38, 5, 91, 59, 0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84, 14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77, 25, 37, 81, 46, 39, 65, 58, 12, 88, 70, 87, 36, 21, 83, 9, 96, 67, 64, 47, 44]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 169M/169M [01:33<00:00, 1.81MB/s]
Input size = [3, 32, 32] 
Task info = [(0, 5), (1, 5), (2, 5), (3, 5), (4, 5), (5, 5), (6, 5), (7, 5), (8, 5), (9, 5), (10, 5), (11, 5), (12, 5), (13, 5), (14, 5), (15, 5), (16, 5), (17, 5), (18, 5), (19, 5)]
Inits...
[BasicBlock(
  (conv1): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (downsample): Sequential(
    (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
), BasicBlock(
  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)   
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
), BasicBlock(
  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)]
[BasicBlock(
  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (downsample): Sequential(
    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
), BasicBlock(
  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
), BasicBlock(
  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)]
[BasicBlock(
  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (downsample): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
), BasicBlock(
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
), BasicBlock(
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)]
----------------------------------------------------------------------------------------------------
WideResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      
      (downsample): Sequential(
        (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleList(
    (0-19): 20 x Linear(in_features=512, out_features=5, bias=True)
  )
)
Dimensions = torch.Size([16, 3, 3, 3]) torch.Size([16]) torch.Size([16]) torch.Size([128, 16, 3, 3]) torch.Size([128]) torch.Size([128]) torch.Size([128, 128, 3, 3]) torch.Size([128]) torch.Size([128]) torch.Size([128, 16, 1, 1]) torch.Size([128]) torch.Size([128]) torch.Size([128, 128, 3, 3]) torch.Size([128]) torch.Size([128]) torch.Size([128, 128, 3, 3]) torch.Size([128]) torch.Size([128]) torch.Size([128, 128, 3, 3]) torch.Size([128]) torch.Size([128]) torch.Size([128, 128, 3, 3]) torch.Size([128]) torch.Size([128]) torch.Size([256, 128, 3, 3]) torch.Size([256]) torch.Size([256]) torch.Size([256, 256, 3, 3]) torch.Size([256]) torch.Size([256]) torch.Size([256, 128, 1, 1]) torch.Size([256]) torch.Size([256]) torch.Size([256, 256, 3, 3]) torch.Size([256]) torch.Size([256]) torch.Size([256, 256, 3, 3]) torch.Size([256]) torch.Size([256]) torch.Size([256, 256, 3, 3]) torch.Size([256]) torch.Size([256]) torch.Size([256, 256, 3, 3]) torch.Size([256]) torch.Size([256]) torch.Size([512, 256, 3, 3]) torch.Size([512]) torch.Size([512]) torch.Size([512, 512, 3, 3]) torch.Size([512]) torch.Size([512]) torch.Size([512, 256, 1, 1]) torch.Size([512]) torch.Size([512]) torch.Size([512, 512, 3, 3]) torch.Size([512]) torch.Size([512]) torch.Size([512, 512, 3, 3]) torch.Size([512]) torch.Size([512]) torch.Size([512, 512, 3, 3]) torch.Size([512]) torch.Size([512]) torch.Size([512, 512, 3, 3]) torch.Size([512]) torch.Size([512]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) torch.Size([5, 512]) torch.Size([5]) 
Num parameters = 17.2M
----------------------------------------------------------------------------------------------------
Setting parameters to ['1', '2']
<bound method Appr.criterion of <approaches.lwf.Appr object at 0x7641477e33b0>>
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
) = lr: 0.01, momentum: 0.9, dampening: 0, weight_decay: 0, nesterov: False, maximize: False, foreach: None, differentiable: False, fused: None, 
----------------------------------------------------------------------------------------------------
****************************************************************************************************
Task  0 (cifar100-0)
Task  0 classes: [26, 86, 2, 55, 75]
****************************************************************************************************
  0%|                                                                                                                                                                         | 0/36 [00:00<?, ?it/s]/home/herocod/Documents/UniPi/SEAI/SEAIProject/In_defence_of_LWF/hat/src/approaches/lwf.py:117: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.
  torch.nn.utils.clip_grad_norm(self.model.parameters(),self.clipgrad)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  7.27it/s]
/home/herocod/Documents/UniPi/SEAI/SEAIProject/In_defence_of_LWF/hat/src/approaches/lwf.py:135: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  images=torch.autograd.Variable(x[b],volatile=True)
/home/herocod/Documents/UniPi/SEAI/SEAIProject/In_defence_of_LWF/hat/src/approaches/lwf.py:136: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  targets=torch.autograd.Variable(y[b],volatile=True)
| Epoch   1, time=141.0ms/ 33.6ms | Train: loss=1.372, acc= 40.1% | Valid: loss=1.445, acc= 35.2% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.84it/s]
| Epoch   2, time=116.1ms/ 32.1ms | Train: loss=1.289, acc= 50.0% | Valid: loss=1.390, acc= 45.2% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.82it/s]
| Epoch   3, time=116.4ms/ 32.2ms | Train: loss=1.247, acc= 52.4% | Valid: loss=1.339, acc= 44.4% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.80it/s]
| Epoch   4, time=116.7ms/ 32.3ms | Train: loss=1.266, acc= 47.2% | Valid: loss=1.348, acc= 44.8% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.82it/s]
| Epoch   5, time=116.4ms/ 32.3ms | Train: loss=1.258, acc= 50.7% | Valid: loss=1.378, acc= 46.4% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.85it/s]
| Epoch   6, time=116.0ms/ 32.3ms | Train: loss=1.208, acc= 52.2% | Valid: loss=1.343, acc= 41.6% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.87it/s]
| Epoch   7, time=115.8ms/ 32.5ms | Train: loss=1.345, acc= 48.5% | Valid: loss=1.525, acc= 44.8% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.77it/s]
| Epoch   8, time=117.1ms/ 32.3ms | Train: loss=1.164, acc= 54.6% | Valid: loss=1.267, acc= 45.6% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.81it/s]
| Epoch   9, time=116.5ms/ 32.4ms | Train: loss=1.126, acc= 56.2% | Valid: loss=1.184, acc= 50.0% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.65it/s]
| Epoch  10, time=118.9ms/ 32.4ms | Train: loss=1.155, acc= 55.0% | Valid: loss=1.250, acc= 50.8% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.74it/s]
| Epoch  11, time=117.5ms/ 32.4ms | Train: loss=1.119, acc= 56.8% | Valid: loss=1.229, acc= 51.2% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.71it/s]
| Epoch  12, time=117.9ms/ 32.4ms | Train: loss=1.158, acc= 55.1% | Valid: loss=1.266, acc= 50.4% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.62it/s]
| Epoch  13, time=119.1ms/ 32.5ms | Train: loss=1.120, acc= 58.4% | Valid: loss=1.167, acc= 52.0% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.75it/s]
| Epoch  14, time=117.4ms/ 32.6ms | Train: loss=1.078, acc= 60.1% | Valid: loss=1.139, acc= 53.6% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.60it/s]
| Epoch  15, time=119.3ms/ 32.6ms | Train: loss=1.074, acc= 58.8% | Valid: loss=1.103, acc= 53.2% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.76it/s]
| Epoch  16, time=117.3ms/ 32.5ms | Train: loss=0.988, acc= 63.6% | Valid: loss=1.082, acc= 58.8% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.70it/s]
| Epoch  17, time=118.3ms/ 32.5ms | Train: loss=1.159, acc= 56.6% | Valid: loss=1.190, acc= 53.2% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.72it/s]
| Epoch  18, time=117.7ms/ 32.5ms | Train: loss=0.989, acc= 61.6% | Valid: loss=1.072, acc= 56.8% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.59it/s]
| Epoch  19, time=119.7ms/ 32.5ms | Train: loss=0.993, acc= 63.8% | Valid: loss=1.059, acc= 59.2% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.63it/s]
| Epoch  20, time=119.0ms/ 32.6ms | Train: loss=0.910, acc= 66.6% | Valid: loss=1.042, acc= 58.0% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  7.55it/s]
| Epoch  21, time=136.1ms/ 42.9ms | Train: loss=0.926, acc= 66.1% | Valid: loss=1.055, acc= 60.0% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  7.54it/s]
| Epoch  22, time=136.2ms/ 38.9ms | Train: loss=0.936, acc= 65.5% | Valid: loss=1.077, acc= 58.0% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  7.32it/s]
| Epoch  23, time=140.3ms/ 35.8ms | Train: loss=0.877, acc= 67.6% | Valid: loss=0.982, acc= 60.4% | *
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  7.33it/s]
| Epoch  24, time=140.1ms/ 34.2ms | Train: loss=0.993, acc= 62.4% | Valid: loss=1.143, acc= 54.4% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:15<00:00,  2.34it/s]
| Epoch  25, time=438.4ms/ 47.2ms | Train: loss=0.930, acc= 65.2% | Valid: loss=1.070, acc= 55.6% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:05<00:00,  6.96it/s]
| Epoch  26, time=148.6ms/ 32.6ms | Train: loss=0.907, acc= 66.0% | Valid: loss=1.009, acc= 61.6% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.75it/s]
| Epoch  27, time=117.4ms/ 32.4ms | Train: loss=0.989, acc= 63.6% | Valid: loss=1.155, acc= 56.8% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.78it/s]
| Epoch  28, time=116.9ms/ 32.5ms | Train: loss=1.015, acc= 62.8% | Valid: loss=1.235, acc= 59.6% |
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  8.83it/s]
| Epoch  29, time=116.3ms/ 32.8ms | Train: loss=0.904, acc= 65.0% | Valid: loss=1.067, acc= 58.4% |
 42%|██████████████████████████████████████████████████████████████████▋                                                                                             | 15/36 [00:01<00:02,  9.12it/s]